{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "535ef657",
   "metadata": {
    "papermill": {
     "duration": 0.00368,
     "end_time": "2024-03-21T13:48:35.155506",
     "exception": false,
     "start_time": "2024-03-21T13:48:35.151826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conceitos e técnicas de Processamento de Linguagem Natural (PLN)\n",
    "\n",
    "O Processamento de Linguagem Natural (PLN) (ou do inglês *Natural language processing (NLP)*) é uma subárea da Ciência da Computação que\n",
    "tem o seu foco em estudos voltados para a geração e compreensão automática da linguagem natural.\n",
    "\n",
    "Quando o objetivo é a compreensão da linguagem natural, faz-se necessário converter a linguagem humana em uma representação formal que possa ser manipulada por sistemas computacionais. \n",
    "\n",
    "Quando a linguagem natural está expressa na forma textual, a primeira iniciativa para se obter uma representação\n",
    "formal que possa ser processada por um computador é a de pré-processamento do texto. A seguir são\n",
    "apresentadas algumas das possíveis etapas de pré-processamento de um texto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc372e64",
   "metadata": {
    "papermill": {
     "duration": 0.002907,
     "end_time": "2024-03-21T13:48:35.161890",
     "exception": false,
     "start_time": "2024-03-21T13:48:35.158983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tokenização\n",
    "\n",
    "A tokenização tem como objetivo a separação de uma sequência de caracteres utilizando os espaços, quebras de linha e/ou pontuações como delimitadores. Geralmente essa é a primeira etapa executada durante o pré-processamento de um texto, servindo como base para as etapas seguintes. A tokenização pode ser efetuada com o objetivo de segmentar os caracteres, as palavras ou até mesmo as sentenças, dependendendo da necessidade específica. Um das bibliotecas disponíveis em python com várias ferramentas de tokenização é a NLTK. Execute o código abaixo com uma mesma frase tokenizada de várias formas diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f990d1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T13:48:35.170224Z",
     "iopub.status.busy": "2024-03-21T13:48:35.169533Z",
     "iopub.status.idle": "2024-03-21T13:48:37.382553Z",
     "shell.execute_reply": "2024-03-21T13:48:37.381070Z"
    },
    "papermill": {
     "duration": 2.219749,
     "end_time": "2024-03-21T13:48:37.384764",
     "exception": false,
     "start_time": "2024-03-21T13:48:35.165015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenização a nível de frases: \n",
      "O sol brilha forte no céu azul. | Uma suave brisa balança as folhas das árvores. | Enquanto isso, as crianças correm alegremente pelo parque.\n",
      "===============================\n",
      "Tokenização a nível de palavras: \n",
      "O | sol | brilha | forte | no | céu | azul | . | Uma | suave | brisa | balança | as | folhas | das | árvores | . | Enquanto | isso | , | as | crianças | correm | alegremente | pelo | parque | .\n",
      "===============================\n",
      "Tokenização com delimitador específico: \n",
      "O sol brilha forte no céu azul. Uma suave brisa balança as folhas das árvores. Enquanto isso |  as crianças correm alegremente pelo parque.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "texto = \"O sol brilha forte no céu azul. Uma suave brisa balança as folhas das árvores. Enquanto isso, as crianças correm alegremente pelo parque.\"\n",
    "\n",
    "frases = sent_tokenize(texto)\n",
    "print(\"Tokenização a nível de frases: \")\n",
    "print(\" | \".join(frases))\n",
    "print(\"===============================\")\n",
    "palavras = word_tokenize(texto)\n",
    "print(\"Tokenização a nível de palavras: \")\n",
    "print(\" | \".join(palavras))\n",
    "print(\"===============================\")\n",
    "#Usando um delimitador especial\n",
    "delimit = texto.split(\",\")\n",
    "print(\"Tokenização com delimitador específico: \")\n",
    "print(\" | \".join(delimit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aa5102",
   "metadata": {
    "papermill": {
     "duration": 0.003198,
     "end_time": "2024-03-21T13:48:37.391535",
     "exception": false,
     "start_time": "2024-03-21T13:48:37.388337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## N-Gramas\n",
    "\n",
    "Um n-grama pode ser considerado uma sequência contígua de *n* itens obtidos a partir de um texto. Esses itens podem ser palavras, caracteres ou outros símbolos presentes no texto. O valor de *n* é definido pelo usuário, sendo os mais comuns *n=1* (unigramas), *n=2* (bigramas) e *n=3* (trigramas). O código abaixo mostra os unigramas e bigramas de caracteres obtidos a partir da frase: \"Olá, como vc está?\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "105cc935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T13:48:37.401230Z",
     "iopub.status.busy": "2024-03-21T13:48:37.399756Z",
     "iopub.status.idle": "2024-03-21T13:48:37.407899Z",
     "shell.execute_reply": "2024-03-21T13:48:37.406615Z"
    },
    "papermill": {
     "duration": 0.015204,
     "end_time": "2024-03-21T13:48:37.410054",
     "exception": false,
     "start_time": "2024-03-21T13:48:37.394850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigramas : O | l | á | , |   | c | o | m | o |   | v | c |   | e | s | t | á\n",
      "Bigramas:  Ol | lá | á, | ,  |  c | co | om | mo | o  |  v | vc | c  |  e | es | st | tá | á?\n"
     ]
    }
   ],
   "source": [
    "frase = \"Olá, como vc está?\"\n",
    "\n",
    "unigrams = [frase[i:i+1] for i in range(len(frase)-1)]\n",
    "bigrams = [frase[i:i+2] for i in range(len(frase)-1)]\n",
    "\n",
    "print(\"Unigramas :\",\" | \".join(unigrams))\n",
    "print(\"Bigramas: \",\" | \".join(bigrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61c5df1",
   "metadata": {
    "papermill": {
     "duration": 0.003191,
     "end_time": "2024-03-21T13:48:37.416802",
     "exception": false,
     "start_time": "2024-03-21T13:48:37.413611",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Remoção de Stopwords\n",
    "\n",
    "Stopwords são palavras que ocorrem muito frequentemente em um texto, ou seja, palavras comuns em uma determinada língua. Alguns exemplos de stopwords são pronomes, preposições, artigos etc. Em alguns casos, esse tipo de palavra não contribui no processamento de linguagem natural e, por isso, podem ser removidas. Isso pode diminuir consideravelmente a quantidade de palavras no texto, o que pode ser uma vantagem do ponto de vista computacional, pois a remoção de palavras comuns tende a reduzir a dimensionalidade dos dados. No exemplo abaixo podemos ver as *stopwords* presentes no texto. Mais uma vez, utilizaremos a biblioteca NLTK para nos ajudar com essa tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b068e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T13:48:37.425724Z",
     "iopub.status.busy": "2024-03-21T13:48:37.425061Z",
     "iopub.status.idle": "2024-03-21T13:48:37.515644Z",
     "shell.execute_reply": "2024-03-21T13:48:37.514750Z"
    },
    "papermill": {
     "duration": 0.09776,
     "end_time": "2024-03-21T13:48:37.517977",
     "exception": false,
     "start_time": "2024-03-21T13:48:37.420217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original:  O sol brilha forte no céu azul. Uma suave brisa balança as folhas das árvores. Enquanto isso, as crianças correm alegremente pelo parque.\n",
      "Stopwords:  O, no, Uma, as, das, isso, as, pelo\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# É necessário o download da lista de stopwords em português\n",
    "nltk.download('stopwords',quiet=True)\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    " \n",
    "word_tokens = word_tokenize(texto)\n",
    "filtered_sentence = [w for w in word_tokens if w.lower() in stop_words]\n",
    "print(\"Texto original: \",texto)\n",
    "print(\"Stopwords: \",\", \".join(filtered_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b67dc1",
   "metadata": {
    "papermill": {
     "duration": 0.003289,
     "end_time": "2024-03-21T13:48:37.524887",
     "exception": false,
     "start_time": "2024-03-21T13:48:37.521598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Lematização\n",
    "\n",
    "O lema de uma palavra pode ser considerado sua forma \"dicionarizada\", ou seja, quando a palavra é representada pelo singular masculino para\n",
    "substantivos e adjetivos e infinitivo para verbos. A palavra \"gostaria\", por exemplo, tem como seu lema a palavra \"gostar\". O exemplo abaixo mostra a lematização de um pequeno texto. Para este exemplo, utilizaremos a biblioteca *spacy*, que contém várias ferramentas para trabalharmos com PLN, inclusive a lematização na língua portuguesa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b0bdb4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T13:48:37.533763Z",
     "iopub.status.busy": "2024-03-21T13:48:37.533129Z",
     "iopub.status.idle": "2024-03-21T13:49:29.496193Z",
     "shell.execute_reply": "2024-03-21T13:49:29.495088Z"
    },
    "papermill": {
     "duration": 51.970413,
     "end_time": "2024-03-21T13:49:29.498709",
     "exception": false,
     "start_time": "2024-03-21T13:48:37.528296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the package via spacy.load('pt_core_news_lg')\r\n",
      "Texto :\n",
      "O sol brilha forte no céu azul. Uma suave brisa balança as folhas das árvores. Enquanto isso, as crianças correm alegremente pelo parque. \n",
      "\n",
      "Palavra: O | Lema(s): o\n",
      "Palavra: sol | Lema(s): sol\n",
      "Palavra: brilha | Lema(s): brilhar\n",
      "Palavra: forte | Lema(s): forte\n",
      "Palavra: no | Lema(s): em o\n",
      "Palavra: céu | Lema(s): céu\n",
      "Palavra: azul | Lema(s): azul\n",
      "Palavra: Uma | Lema(s): um\n",
      "Palavra: suave | Lema(s): suave\n",
      "Palavra: brisa | Lema(s): brisa\n",
      "Palavra: balança | Lema(s): balançar\n",
      "Palavra: as | Lema(s): o\n",
      "Palavra: folhas | Lema(s): folha\n",
      "Palavra: das | Lema(s): de o\n",
      "Palavra: árvores | Lema(s): árvore\n",
      "Palavra: Enquanto | Lema(s): enquanto\n",
      "Palavra: isso | Lema(s): isso\n",
      "Palavra: as | Lema(s): o\n",
      "Palavra: crianças | Lema(s): criança\n",
      "Palavra: correm | Lema(s): correr\n",
      "Palavra: alegremente | Lema(s): alegremente\n",
      "Palavra: pelo | Lema(s): por o\n",
      "Palavra: parque | Lema(s): parque\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet spacy\n",
    "!python -m spacy download pt_core_news_lg --quiet \n",
    "\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_lg\")\n",
    "doc = nlp(texto)\n",
    "\n",
    "print(\"Texto :\")\n",
    "print(texto,\"\\n\")\n",
    "\n",
    "for w in doc:\n",
    "    if w.text not in string.punctuation:\n",
    "        print(\"Palavra: {} | Lema(s): {}\".format(w.text,w.lemma_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f86e95",
   "metadata": {
    "papermill": {
     "duration": 0.003333,
     "end_time": "2024-03-21T13:49:29.505706",
     "exception": false,
     "start_time": "2024-03-21T13:49:29.502373",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7638de11",
   "metadata": {
    "papermill": {
     "duration": 0.003317,
     "end_time": "2024-03-21T13:49:29.512575",
     "exception": false,
     "start_time": "2024-03-21T13:49:29.509258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Etiquetagem Morfológica\n",
    "\n",
    "A sintaxe de um idioma é o conjunto de regras que tem como objetivo dar sentido gramatical a um conjunto de palavras. A etiquetagem\n",
    "morfológica (part of speech – POS) consiste na análise da função gramatical de cada palavra numa frase. A língua portuguesa, por exemplo, é composta por 10 classes de palavras (adjetivos, advérbios, artigos, conjunções, interjeições, numerais, preposições, pronomes, substantivos e verbos), porém, mais classes podem ser utilizadas durante a etiquetagem morfológica. Mais uma vez, a biblioteca *spacy* faz a etiquetagem para o idioma português, como é possível ver no exemplo abaixo. Além disso, você pode verificar o significado de cada tag do exemplo [aqui](https://universaldependencies.org/u/pos/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2d9d7bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T13:49:29.521515Z",
     "iopub.status.busy": "2024-03-21T13:49:29.520983Z",
     "iopub.status.idle": "2024-03-21T13:49:29.527483Z",
     "shell.execute_reply": "2024-03-21T13:49:29.526380Z"
    },
    "papermill": {
     "duration": 0.013924,
     "end_time": "2024-03-21T13:49:29.530123",
     "exception": false,
     "start_time": "2024-03-21T13:49:29.516199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavra: O | Etiqueta Morfológica : DET\n",
      "Palavra: sol | Etiqueta Morfológica : NOUN\n",
      "Palavra: brilha | Etiqueta Morfológica : VERB\n",
      "Palavra: forte | Etiqueta Morfológica : ADJ\n",
      "Palavra: no | Etiqueta Morfológica : ADP\n",
      "Palavra: céu | Etiqueta Morfológica : NOUN\n",
      "Palavra: azul | Etiqueta Morfológica : ADJ\n",
      "Palavra: . | Etiqueta Morfológica : PUNCT\n",
      "Palavra: Uma | Etiqueta Morfológica : DET\n",
      "Palavra: suave | Etiqueta Morfológica : ADJ\n",
      "Palavra: brisa | Etiqueta Morfológica : NOUN\n",
      "Palavra: balança | Etiqueta Morfológica : VERB\n",
      "Palavra: as | Etiqueta Morfológica : DET\n",
      "Palavra: folhas | Etiqueta Morfológica : NOUN\n",
      "Palavra: das | Etiqueta Morfológica : ADP\n",
      "Palavra: árvores | Etiqueta Morfológica : NOUN\n",
      "Palavra: . | Etiqueta Morfológica : PUNCT\n",
      "Palavra: Enquanto | Etiqueta Morfológica : ADP\n",
      "Palavra: isso | Etiqueta Morfológica : PRON\n",
      "Palavra: , | Etiqueta Morfológica : PUNCT\n",
      "Palavra: as | Etiqueta Morfológica : DET\n",
      "Palavra: crianças | Etiqueta Morfológica : NOUN\n",
      "Palavra: correm | Etiqueta Morfológica : VERB\n",
      "Palavra: alegremente | Etiqueta Morfológica : ADV\n",
      "Palavra: pelo | Etiqueta Morfológica : ADP\n",
      "Palavra: parque | Etiqueta Morfológica : NOUN\n",
      "Palavra: . | Etiqueta Morfológica : PUNCT\n"
     ]
    }
   ],
   "source": [
    "for w in doc:\n",
    "    print(\"Palavra: {} | Etiqueta Morfológica : {}\".format(w.text,w.pos_))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 58.467479,
   "end_time": "2024-03-21T13:49:30.757011",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-21T13:48:32.289532",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
